{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro Credit Loan Defaulter Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem Statement: \n",
    "A Microfinance Institution (MFI) is an organization that offers financial services to low income populations. MFS becomes very useful when targeting especially the unbanked poor families living in remote areas with not much sources of income. The Microfinance services (MFS) provided by MFI are Group Loans, Agricultural Loans, Individual Business Loans and so on. \n",
    "Many microfinance institutions (MFI), experts and donors are supporting the idea of using mobile financial services (MFS) which they feel are more convenient and efficient, and cost saving, than the traditional high-touch model used since long for the purpose of delivering microfinance services. Though, the MFI industry is primarily focusing on low income families and are very useful in such areas, the implementation of MFS has been uneven with both significant challenges and successes.\n",
    "Today, microfinance is widely accepted as a poverty-reduction tool, representing $70 billion in outstanding loans and a global outreach of 200 million clients.\n",
    "We are working with one such client that is in Telecom Industry. They are a fixed wireless telecommunications network provider. They have launched various products and have developed its business and organization based on the budget operator model, offering better products at Lower Prices to all value conscious customers through a strategy of disruptive innovation that focuses on the subscriber. \n",
    "They understand the importance of communication and how it affects a person’s life, thus, focusing on providing their services and products to low income families and poor customers that can help them in the need of hour. \n",
    "They are collaborating with an MFI to provide micro-credit on mobile balances to be paid back in 5 days. The Consumer is believed to be defaulter if he deviates from the path of paying back the loaned amount within the time duration of 5 days. For the loan amount of 5 (in Indonesian Rupiah), payback amount should be 6 (in Indonesian Rupiah), while, for the loan amount of 10 (in Indonesian Rupiah), the payback amount should be 12 (in Indonesian Rupiah). \n",
    "The sample data is provided to us from our client database. It is hereby given to you for this exercise. In order to improve the selection of customers for the credit, the client wants some predictions that could help them in further investment and improvement in selection of customers. \n",
    "Exercise:\n",
    "Build a model which can be used to predict in terms of a probability for each loan transaction, whether the customer will be paying back the loaned amount within 5 days of insurance of loan. In this case, Label ‘1’ indicates that the loan has been payed i.e. Non- defaulter, while, Label ‘0’ indicates that the loan has not been payed i.e. defaulter.  \n",
    "Points to Remember:\n",
    "•\tThere are no null values in the dataset. \n",
    "•\tThere may be some customers with no loan history. \n",
    "•\tThe dataset is imbalanced. Label ‘1’ has approximately 87.5% records, while, label ‘0’ has approximately 12.5% records.\n",
    "•\tFor some features, there may be values which might not be realistic. You may have to observe them and treat them with a suitable explanation.\n",
    "•\tYou might come across outliers in some features which you need to handle as per your understanding. Keep in mind that data is expensive and we cannot lose more than 7-8% of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Micro_Credit_Loan_Data_file.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the 1st column as it is not necessary, only contains serial no.\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total 36 columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "#No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdate should be of date type\n",
    "df['pdate']= pd.to_datetime(df['pdate'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Lets check the number of distict values in for column of object datatype \n",
    "for col in df.columns:\n",
    "    if df[col].dtype==\"object\":\n",
    "        print(\"column name is: {} and number of distict values: {}\".format(col,len(df[col].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "#Presence of outliers in some columns like last_rech_date_ma, last_rech_date_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As observed in minimum values above-\n",
    "#aon (age on cellular network in days) cannot be negative\n",
    "#daily_decr30 (Daily amount spent from main account, averaged over last 30 days (in Indonesian Rupiah)) \n",
    "#and daily_decr90 (Daily amount spent from main account, averaged over last 90 days (in Indonesian Rupiah)) cannot be negative.\n",
    "\n",
    "#last_rech_date_ma (Number of days till last recharge of main account)\n",
    "#and last_rech_date_da (Number of days till last recharge of data account) cannot be negative.\n",
    "\n",
    "#Also, rental30(Average main account balance over last 30 days) and \n",
    "#rental90(Average main account balance over last 90 days) being negative are not favorable to provide them credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing negative values with zero\n",
    "df = df._get_numeric_data()\n",
    "df[df<0] = 0\n",
    "df.describe()\n",
    "\n",
    "\n",
    "#All negative values are now replaced with zero\n",
    "#Or Impute these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with 'label' column\n",
    "df['label'].unique()\n",
    "#Binary values in target 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imbalanced dataset in target\n",
    "df.label.value_counts()\n",
    "#imbalanced dataset problem so we can use SMOTE just to increase instances of minority classes in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(x='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(data=df.daily_decr30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.boxplot(data=df.iloc[:,1:9], orient=\"h\", palette=\"Set1\")\n",
    "#Presence of outliers in many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/shrutidandagi/eda-bank-loan-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total amount of recharges vs amount of loans taken versus default (cont. vs cont. vs cat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 30 days-\n",
    "#sumamnt_ma_rech30\tTotal amount of recharge in main account over last 30 days (in Indonesian Rupiah)\n",
    "#amnt_loans30\tTotal amount of loans taken by user in last 30 days\n",
    "#versus label\n",
    "#3 columns- 2 continuous and 1 categorical(as hue)\n",
    "sns.relplot(x=\"amnt_loans30\", y=\"sumamnt_ma_rech30\", hue=\"label\", kind=\"line\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 90 days-\n",
    "#sumamnt_ma_rech90\tTotal amount of recharge in main account over last 90 days (in Indonasian Rupiah)\n",
    "#amnt_loans90\tTotal amount of loans taken by user in last 90 days\n",
    "#versus label\n",
    "\n",
    "#3 columns- 2 continuous and 1 categorical(as hue)\n",
    "sns.relplot(x=\"amnt_loans90\", y=\"sumamnt_ma_rech90\", hue=\"label\", kind=\"line\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recharge frequency/no. of times of recharging versus no. of loans taken vs default (cont. vs cont. vs cat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 30 days-\n",
    "#cnt_ma_rech30\tNumber of times main account got recharged in last 30 days\n",
    "#cnt_loans30\tNumber of loans taken by user in last 30 days\n",
    "#versus label\n",
    "sns.relplot(x=\"cnt_loans30\", y=\"cnt_ma_rech30\", hue=\"label\", kind=\"line\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max. loan vs payback time vs default(cont. vs cont. vs cat.)\n",
    "#There are only two options: 5 & 10 Rs., for which the user needs to pay back 6 & 12 Rs. respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 30 days-\n",
    "#amnt_loans30\tTotal amount of loans taken by user in last 30 days\n",
    "#payback30\tAverage payback time in days over last 30 days\n",
    "#versus label\n",
    "\n",
    "#sns.displot(df, x=\"maxamnt_loans30\", hue=\"label\", multiple=\"dodge\")\n",
    "#sns.relplot(x=\"payback30\", y=\"maxamnt_loans30\", hue=\"label\", kind=\"line\", data=df)\n",
    "#df[\"payback30\"].plot.hist(bins=10, figsize=(10,8))\n",
    "\n",
    "sns.displot(df, x=\"amnt_loans30\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 90 days-\n",
    "#maxamnt_loans90\tmaximum amount of loan taken by the user in last 90 days\n",
    "#payback90\tAverage payback time in days over last 90 days\n",
    "#versus label\n",
    "#sns.relplot(x=\"maxamnt_loans90\", y=\"payback90\", hue=\"label\", kind=\"line\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average main account balance vs no. of loans taken vs payback time (cont. vs cont. vs cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 30 days-\n",
    "#rental30\tAverage main account balance over last 30 days\n",
    "#cnt_loans30\tNumber of loans taken by user in last 30 days\n",
    "#payback30\tAverage payback time in days over last 30 days\n",
    "\n",
    "#Two columns (cont. var.) on same x-axis but different y-axis\n",
    "#df.plot(x=\"rental30\", y=\"cnt_loans30\")\n",
    "#ax = df.plot(secondary_y=\"payback30\")\n",
    "\n",
    "\n",
    "#df[\"cnt_loans90\"].plot(secondary_y=True, style=\"g\")  #Use of keyword\n",
    "#Four columns (cont. var.) on two y-axis\n",
    "#plt.figure()\n",
    "#ax = df.plot(secondary_y=[\"A\", \"B\"]) #Two columns on one y-axis\n",
    "#ax.set_ylabel(\"CD scale\")    #Other two columns on other y-axis\n",
    "#ax.right_ax.set_ylabel(\"AB scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 90 days-\n",
    "#rental90\tAverage main account balance over last 90 days\n",
    "#cnt_loans90\tNumber of loans taken by user in last 90 days\n",
    "#payback90\tAverage payback time in days over last 90 days\n",
    "df.plot(x=\"rental90\", y=\"cnt_loans90\")\n",
    "plt.figure()\n",
    "ax = df.plot(secondary_y=\"payback90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main account vs data account recharge (cont. vs cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 30 days-\n",
    "#cnt_ma_rech30\tNumber of times main account got recharged in last 30 days\n",
    "#versus\n",
    "#cnt_da_rech30\tNumber of times data account got recharged in last 30 days\n",
    "#df[\"cnt_ma_rech30\"].plot()\n",
    "#df[\"cnt_da_rech30\"].plot(secondary_y=True, style=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 90 days-\n",
    "#cnt_ma_rech90\tNumber of times main account got recharged in last 90 days\n",
    "#versus\n",
    "#cnt_da_rech90\tNumber of times data account got recharged in last 90 days\n",
    "df[\"cnt_ma_rech30\"].plot()\n",
    "df[\"cnt_da_rech30\"].plot(secondary_y=True, style=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of main and data recharge vs no. of loans (cont vs cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fr_ma_rech30\tFrequency of main account recharged in last 30 days\n",
    "#versus\n",
    "#cnt_loans30\tNumber of loans taken by user in last 30 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fr_da_rech30\tFrequency of data account recharged in last 30 days\n",
    "#versus\n",
    "#cnt_loans30\tNumber of loans taken by user in last 30 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of days till last recharge of main account and vs Number of days till last recharge of data account (cont. vs cont.)\n",
    "#last_rech_date_ma\tNumber of days till last recharge of main account\n",
    "#last_rech_date_da\tNumber of days till last recharge of data account\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 30 days-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For and 90 days-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main account-related- \n",
    "#This will give insight into if there is relation between daily spendings and recharge frequencies and amount.\n",
    "#With label as hue for defaulter\n",
    "#(if default is done more by those having high no. of recharges of main account or for a specific amount of recharge.)\n",
    "\n",
    "#versus label-\n",
    "1. # medianamnt_ma_rech30\tMedian of amount of recharges done in main account over last 30 days at user level (in Indonesian Rupiah)\n",
    "# and  medianamnt_ma_rech90\tMedian of amount of recharges done in main account over last 90 days at user level (in Indonasian Rupiah)\n",
    "\n",
    "2. #daily_decr30\tDaily amount spent from main account, averaged over last 30 days (in Indonesian Rupiah) and \n",
    "#daily_decr90\tDaily amount spent from main account, averaged over last 90 days (in Indonesian Rupiah) versus label\n",
    "\n",
    "\n",
    "#Do it in tight layout/subplot\n",
    "\n",
    "plt.figure(figsize = (10, 15))\n",
    "sns.displot(df, x=\"medianamnt_ma_rech30\", hue=\"label\", kind=\"kde\")\n",
    "\n",
    "sns.displot(df, x=\"medianamnt_ma_rech90\", hue=\"label\", kind=\"kde\")\n",
    "\n",
    "#For 30 days data-\n",
    "#Defaulters, most of the recharges are done in range of 0 to 4000 rupiah\n",
    "#Non-defaulters, most of the recharges are done roughly in range of 0 to 8000 rupiah\n",
    "#For 90 days data- Shows the same trend.\n",
    "#No significant relation\n",
    "\n",
    "plt.figure(figsize = (10, 15))\n",
    "sns.displot(df, x=\"daily_decr30\", hue=\"label\", kind=\"kde\")\n",
    "sns.displot(df, x=\"daily_decr90\", hue=\"label\", kind=\"kde\")\n",
    "#For both data of 30 and 90 days, defaulters spend lesser money from main account than non-defaulters.\n",
    "#Most defaulters spend roughly 0 to 5000 rupiah as against majority of non-defaulters who spend upto roughly 40000 rupiah daily from main account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation 1.\n",
    "#Non- defaulters spend more amount from main account along with doing more amount of recharges as compared to defaulters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try histogram (Histplot)\n",
    "\n",
    "df.hist(by='label', column='payback30')\n",
    "#Syntax- by='cat. var', column='cont. var.'\n",
    "\n",
    "\n",
    "#Loan-related (resp. for 30 and 90 days)\n",
    "#To check relation between frequency of recharges and loans-\n",
    "#For 30 days-\n",
    "1. #cnt_loans30\tNumber of loans taken by user in last 30 days versus \n",
    "#cnt_ma_rech30\tNumber of times main account got recharged in last 30 days With label as hue for defaulter\n",
    "\n",
    "2.#amnt_loans30\tTotal amount of loans taken by user in last 30 days versus\n",
    "#payback30\tAverage payback time in days over last 30 days With label as hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.lineplot(x=\"cnt_ma_rech30\", y=\"cnt_loans30\", hue=\"label\", data=df)\n",
    "#There is a positive relation between no. of loans and no. of times of recharging main account\n",
    "#Non-defaulters take more no. of loans with increase in no. of recharges but is highly skewed.\n",
    "#Defaulters' max no. of loans stand at approx 26 and max no. of recharges at approx 40, \n",
    "#i.e. they take lesser no. of loans and lesser no. of recharges \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x=\"amnt_loans30\", y=\"payback30\", hue=\"label\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x=\"amnt_loans90\", y=\"payback90\", hue=\"label\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation 2- \n",
    "#Defaulters have higher payback time and that too for lesser amount of loans and vice-versa.\n",
    "#Non-defaulters payback in lesser no. of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recharge-related, \n",
    "#Data account related- deep insight if people are recharging more for internet or calls .\n",
    "#Main account vs data account recharge comparisons\n",
    "1. #cnt_da_rech30\tNumber of times data account got recharged in last 30 days versus\n",
    "#cnt_ma_rech30\tNumber of times main account got recharged in last 30 days\n",
    "\n",
    "#Main account vs data account recharge defaulters\n",
    "\n",
    "3). #last_rech_date_ma\tNumber of days till last recharge of main account and\n",
    "#last_rech_date_da\tNumber of days till last recharge of data account versus label\n",
    "\n",
    "#rental30\tAverage main account balance over last 30 days\n",
    "#rental90\tAverage main account balance over last 90 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"cnt_da_rech30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"cnt_ma_rech30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation 3-\n",
    "#Data account is recharged more than main account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x=\"last_rech_date_da\", y=\"last_rech_date_ma\", hue=\"label\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countplot for target\n",
    "sns.countplot(df['label'])\n",
    "#Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate analysis\n",
    "#pairplot with subplots\n",
    "sns.pairplot(df, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation analysis with corr()\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with heatmap\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df.corr(), annot= True, linewidth=1.0, linecolor=\"black\", fmt='0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking columns which are strongly correlated to target 'label'\n",
    "plt.figure(figsize=(22,7))\n",
    "df.corr()['label'].sort_values(ascending=False).drop(['label']).plot(kind='bar', color='c')\n",
    "plt.xlabel('Feature', fontsize=14)\n",
    "plt.ylabel('Column with target names', fontsize=14)\n",
    "plt.title('Correlation', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking skewness\n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of features which are significantly skewed: \",len(df.skew().loc[abs(df.skew())>0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "#lets use pd.get_dummies function to convert categorical columns into numeric form which machine can uderstand\n",
    "df=pd.get_dummies(df, drop_first = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "#Remove outliers with quantiles or imputing or zscore\n",
    "\n",
    "#Checking outliers with zscore\n",
    "from scipy.stats import zscore\n",
    "z=np.abs(zscore(df))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=3\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers using zscore\n",
    "df_new=df[(z<3).all(axis=1)]\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for percentile in describe method for particular column\n",
    "print(df['aon'].quantile(0.01))\n",
    "print(df['aon'].quantile(0.75))\n",
    "print(df['aon'].quantile(0.99))\n",
    "#each of these give 28.0, 35.0, and 54.7 as respective quantiles value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual otlier removal in column on basis of selected quantile values\n",
    "df['aon']=np.where(df['aon']<0, 55.0, df['aon'])\n",
    "#Outliers removed in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aon'].describe()\n",
    "#Check for the column\n",
    "#Negative values removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%Loss of data\n",
    "Data_loss=((209593-161457)/209593)*100\n",
    "Data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since data loss is more than 8%, so use IQR method to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use IQR method to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing it into input and output\n",
    "x=df_new.drop(\"label\", axis=1)\n",
    "y=df_new[[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check skewness in features\n",
    "x.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove skewness if any with transformation or other method\n",
    "for index in x.skew().index:\n",
    "    if x.skew().loc[index]>0.5:\n",
    "        x[index]=np.log1p(x[index])\n",
    "        if x.skew().loc[index]<-0.5:\n",
    "            x[index]=np.square(x[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data scaling/normalizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stds=StandardScaler()\n",
    "X=stds.fit_transform(x)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating imbalance with SMOTE\n",
    "# import SMOTE module from imblearn library\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2)\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_sm.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_sm.shape))\n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_sm == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_sm == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since it is an imbalanced dataset so we will focus on auc-roc score\n",
    "!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Finding best random state using SMOTE\n",
    "\n",
    "def max_aucroc_score(clfr,x,y):\n",
    "    max_aucroc_score=0\n",
    "    for r_state in range(30,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = r_state,test_size=0.30,stratify=y)\n",
    "        X_train_sm, y_train_sm = SMOTE().fit_sample(X_train, y_train.ravel())\n",
    "        clfr.fit(X_train_sm,y_train_sm)\n",
    "        y_pred = clfr.predict(X_test)\n",
    "        auro_scr=roc_auc_score(y_test,y_pred)\n",
    "        print(\"auc roc score corresponding to \",r_state,\" is \",auro_scr)\n",
    "        if auro_scr>max_aucroc_score:\n",
    "            max_aucroc_score=auro_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max auc roc score corresponding to \",final_r_state,\" is \",max_aucroc_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction and Recall\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr.predict(X_test)\n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(max_aucroc_score(lr,X,y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use cross_val_score for logistic regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(lr,X,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use logistic regression and check\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#lr=LogisticRegression()\n",
    "#max_aucroc_score(lr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier()\n",
    "max_aucroc_score(dtc,df_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check cross_val_score for decision tree\n",
    "print(\"Mean auc roc score for decision tree classifier: \",cross_val_score(dtc,df_x,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in auc roc score for decision tree classifier: \",cross_val_score(dtc,df_x,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(dtc,df_x,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"n_estimators\":[10,100,500]}\n",
    "rfo_clf=RandomForestClassifier()\n",
    "clfs = GridSearchCV(rfo_clf, parameters, cv=5,scoring=\"roc_auc\")\n",
    "clfs.fit(df_x,y)\n",
    "clfs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfo_clf=RandomForestClassifier(n_estimators=500)\n",
    "max_aucroc_score(rfo_clf,df_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check cross_val_score for random forest\n",
    "print(\"Mean auc roc score for random forest classifier: \",cross_val_score(rfo_clf,df_x,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in auc roc score for random forest classifier: \",cross_val_score(rfo_clf,df_x,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(rfo_clf,df_x,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use KNN\n",
    "#For KNN we need to know the best value of k using grid search\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnc=KNeighborsClassifier()\n",
    "neighbors={\"n_neighbors\":range(1,30)}\n",
    "clfs = GridSearchCV(knnc, neighbors, cv=5,scoring=\"roc_auc\")\n",
    "clfs.fit(x,y)\n",
    "clfs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnc=KNeighborsClassifier(n_neighbors=28)\n",
    "max_aucroc_score(knnc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use cross_val_score for knn \n",
    "print(\"Mean roc auc score for knn classifier: \",cross_val_score(knnc,x,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in roc auc score for knn classifier: \",cross_val_score(knnc,x,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(knnc,x,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use SVM\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "parameters={\"kernel\":[\"linear\", \"poly\", \"rbf\"],\"C\":[0.001,0.01,0.1,1,10]}\n",
    "clfs = GridSearchCV(svc, parameters, cv=5,scoring=\"roc_auc\")\n",
    "clfs.fit(x,y)\n",
    "clfs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(kernel=\"linear\",C=0.1)\n",
    "max_aucroc_score(svc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use cross_val_score for svm\n",
    "print(\"Mean roc auc score for svm classifier: \",cross_val_score(svc,x,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in roc auc score for svm classifier: \",cross_val_score(svc,x,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(svc,x,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use Gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "parameters={\"learning_rate\":[0.001,0.01,0.1,1],\"n_estimators\":[10,100,500,1000]}\n",
    "grb_clf=GradientBoostingClassifier()\n",
    "clfs = GridSearchCV(grb_clf, parameters, cv=5,scoring=\"roc_auc\")\n",
    "clfs.fit(df_x,y)\n",
    "clfs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grb_clf=GradientBoostingClassifier(learning_rate=0.1,n_estimators=500)\n",
    "max_aucroc_score(grb_clf,df_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check cross_val_score for gradient boosting\n",
    "print(\"Mean auc roc score for gradient boosting classifier: \",cross_val_score(grb_clf,df_x,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in auc roc score for gradient boosting classifier: \",cross_val_score(grb_clf,df_x,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(grb_clf,df_x,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets choose svm as our final model and random state 70\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state = 70,test_size=0.20,stratify=y)\n",
    "x_train, y_train = SMOTE().fit_sample(x_train, y_train)\n",
    "svc=SVC(kernel=\"linear\",C=0.1)\n",
    "svc.fit(x_train,y_train)\n",
    "y_pred=svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"f1 score is : \",f1_score(y_test,y_pred))\n",
    "print(\"classification report \\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC ROC Score: \",roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check multicollinearity with VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding best random state\n",
    "#Apply the logistic regression model\n",
    "from sklearn.model_selection import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr=LogisticRegression()\n",
    "for i in range(0,10000):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x_scaled, y, test_size=0.30, random_state=i)\n",
    "    lr.fit(x_train, y_train)\n",
    "    #scores of test and train datasets\n",
    "    pred_train=lr.predict(x_train)\n",
    "    pred_test=lr.predict(x_test)\n",
    "    if round(accuracy_score(y_train, pred_train)*100,2)==round(accuracy_score(y_test, pred_test)*100,2):\n",
    "        print(\"At random state\", i, \"this model performs well\")\n",
    "        print(\"Training score is:\", accuracy_score(y_train, pred_train)*100)\n",
    "        print(\"Testing score is:\", accuracy_score(y_test, pred_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Here, the best random state is:\n",
    "#So applying it in another algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for overfitting/underfitting with train and test scores with cross_val_score\n",
    "pred_lr=lr.predict(x_test)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lrs=accuracy_score(y_test, pred_lr)\n",
    "for j in range(2,10):\n",
    "    lrscore=cross_val_score(lr, x_scaled, y, cv=j)\n",
    "    lsc=lrscore.mean()\n",
    "    print(\"At cv:\", j)\n",
    "    print(\"Cross validation score is:\", lsc*100)\n",
    "    print(\"Accuracy score is:\", lrs*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC-ROC value for the above algo\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds=roc_curve(pred_test, y_test)\n",
    "roc_auc=auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=10, label='ROCcurve(area=%0.2f)', %roc_curve)\n",
    "plt.plot([0,1], [0,1], color='navy', lw=10, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Receiver operating characteristics')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization (if needed)\n",
    "#3 more algos with the above random state in train_test_split\n",
    "#Steps till AUC-ROC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best AUC-ROC to find best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
